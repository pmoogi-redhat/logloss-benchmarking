# logloss-benchmarking

This repo used to experience and simulate log loss scenarios using Fluentd

The repo contains simulation script for 
 1. replicating log-loss at different rate of logs generation (msg line per sec or no of bytes per sec)
 2. measuring log-loss at a given setting of log-size-max limits
 
 > Note: The loader and verify-loader scripts are taken from https://github.com/ViaQ/logging-load-driver
 They are further changed to have more debug/print statements for better understanding on log-loss.

## Scenario 1:  logloss-benchmarking using loader and verify-loader programs as standalone setup

 
 > Note: Simulation script can use custom conmon binary which is changed to log in extra metadata on log-rotation event and timestamps
 >
 > ```${LOCALBIN}/podman run --log-level debug --conmon $conmonlatestlib --env MSGPERSEC --env PAYLOAD_GEN --env PAYLOAD_SIZE --env DISTRIBUTION --env STDDEV --env OUTPUT  --env REPORT --env REPORT_INTERVAL --env TOTAL_SIZE --log-opt max-size=$MAXSIZE  $imageid"``` 
 

 Below Results are obtained when setting:  
   `MSGPERSEC = 100`  
   `log-lines per sec = 10000`  
   `pay-load size = 1024 bytes`    
   `payload_gen method as fixed (not random)`   
   `etc.`  
 
 You can replicate these results by running the below scripts:
 
 `simulation-with-diff-config-variables.sh <MSGPERSEC> <MAXSIZE> <TOTALDURATION_OF_RUN>`
 e.g. simulation-with-diff-config-variables.sh 1000 1024000 10 
 
 > [The Above generates 1000 loglines per sec of payload 1024 bytes, maxsize of logfile being 1024000 bytes, REPORT INTERVAL being set to 10 sec by loader program]

|msq-lines-per-sec log generation rate | Rate of writing to disk bytes per sec | Log-max-size limit set to.. | Loss rate(mb per sec) as we see.. |msg-len set to |
|--|--|--|--|--|
|100  | 100*1024=0.1mb| 1mb | 0.012| 1024 |
|--|--|--|--|--|
|1000 | 1000*1024=1mb | 1mb | 0.13 | 1024 |
|--|--|--|--|--|
|2000 | 2000*1024=2mb | 1mb | 0.24 | 1024 |
|--|--|--|--|--|
|3000 | 3000*1024=3mb | 1mb | 0.37 | 1024 |
|--|--|--|--|--|
|4000 | 4000*1024=4mb | 1mb | 0.50 | 1024 |
|--|--|--|--|--|
|5000 | 5000*1024=5mb | 1mb | 0.64 | 1024 |
|--|--|--|--|--|
|6000 | 6000*1024=6mb | 1mb | 0.75 | 1024 |
|--|--|--|--|--|
|7000 | 7000*1024=7mb | 1mb | 0.9  | 1024 |
|--|--|--|--|--|
|8000 | 8000*1024=8mb | 1mb | 1.04 | 1024 |
|--|--|--|--|--|
|9000 |9000*1024=9mb  | 1mb | 1.27 | 1024 |
|--|--|--|--|--|
|10000|10000*1024=10mb|1mb  | 1.3  | 1024 |
|--|--|--|--|--|


## Scenario 2 logloss-benchmarking using loader and fluentd being the log collector
Steps to simulate this scenario:

   1. Install locally fluentd by following [installing-fluentd-readme.md](installing-fluentd-readme.md)
   2. Deploy logging-load-driver docker image  
      `cd logging-load-driver`    
      `make all`  
      `cd ..`  
   3. Start the logging load driver container using run-container-for-logging-load-driver-program.sh   
      `./run-container-for-logging-load-driver-program.sh <MSEPERSEC> <MAXSIZELOGFILE> <REPORT_INTERVAL>`
             
      > e.g `./run-container-for-logging-load-driver-program.sh 100 1000 60`     
   3. Execute fluentd (in different shell)  
      `sudo chmod a=rwx /var/lib/docker/containers`    
      `sudo fluentd -c fluent-test-tail.conf`  
      
      > Note: Need to run fluentd with sudo permission, so will be able to tail root level docker directories     
  
  Log lines generated by loader program in the step 1 gets collected by fluentd which is given fluent-test-tail.conf. The fluent-test-tail.conf must have the right path, position, and other configuration parameters specified.
  please check the content of fluent-test-tail.conf for configuring input and output plugins for fluentd
